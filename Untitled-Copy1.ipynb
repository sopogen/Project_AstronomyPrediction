{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/ybigta_sdss_train.csv', index_col=0)\n",
    "test = pd.read_csv('data/ybigta_sdss_test.csv', index_col=0)\n",
    "sample_submission = pd.read_csv('data/ybigta_sdss_sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_number = {}\n",
    "for i, column in enumerate(sample_submission.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "train['type_num'] = train['type'].apply(lambda x: to_number(x, column_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fiberID</th>\n",
       "      <th>psfMag_u</th>\n",
       "      <th>psfMag_g</th>\n",
       "      <th>psfMag_r</th>\n",
       "      <th>psfMag_i</th>\n",
       "      <th>psfMag_z</th>\n",
       "      <th>fiberMag_u</th>\n",
       "      <th>fiberMag_g</th>\n",
       "      <th>fiberMag_r</th>\n",
       "      <th>fiberMag_i</th>\n",
       "      <th>...</th>\n",
       "      <th>petroMag_u</th>\n",
       "      <th>petroMag_g</th>\n",
       "      <th>petroMag_r</th>\n",
       "      <th>petroMag_i</th>\n",
       "      <th>petroMag_z</th>\n",
       "      <th>modelMag_u</th>\n",
       "      <th>modelMag_g</th>\n",
       "      <th>modelMag_r</th>\n",
       "      <th>modelMag_i</th>\n",
       "      <th>modelMag_z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70379</th>\n",
       "      <td>182</td>\n",
       "      <td>-0.598164</td>\n",
       "      <td>-0.562223</td>\n",
       "      <td>-0.523825</td>\n",
       "      <td>-0.477533</td>\n",
       "      <td>-0.310329</td>\n",
       "      <td>-0.608080</td>\n",
       "      <td>-0.527150</td>\n",
       "      <td>-0.404767</td>\n",
       "      <td>-0.334387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478094</td>\n",
       "      <td>-0.270581</td>\n",
       "      <td>-0.174649</td>\n",
       "      <td>-0.128071</td>\n",
       "      <td>-0.048439</td>\n",
       "      <td>-0.486939</td>\n",
       "      <td>-0.255689</td>\n",
       "      <td>-0.172579</td>\n",
       "      <td>-0.128800</td>\n",
       "      <td>-0.029025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863365</th>\n",
       "      <td>207</td>\n",
       "      <td>1.119119</td>\n",
       "      <td>0.994625</td>\n",
       "      <td>0.513011</td>\n",
       "      <td>0.379657</td>\n",
       "      <td>0.880492</td>\n",
       "      <td>1.220576</td>\n",
       "      <td>1.098720</td>\n",
       "      <td>0.624629</td>\n",
       "      <td>0.501348</td>\n",
       "      <td>...</td>\n",
       "      <td>1.411041</td>\n",
       "      <td>1.119810</td>\n",
       "      <td>0.692548</td>\n",
       "      <td>0.557135</td>\n",
       "      <td>0.774780</td>\n",
       "      <td>1.610314</td>\n",
       "      <td>1.099636</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.549078</td>\n",
       "      <td>0.871485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40381</th>\n",
       "      <td>496</td>\n",
       "      <td>-0.554902</td>\n",
       "      <td>-0.365210</td>\n",
       "      <td>-0.161029</td>\n",
       "      <td>0.063084</td>\n",
       "      <td>0.210503</td>\n",
       "      <td>-0.583157</td>\n",
       "      <td>-0.319391</td>\n",
       "      <td>-0.059566</td>\n",
       "      <td>0.179141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447007</td>\n",
       "      <td>-0.086297</td>\n",
       "      <td>0.132123</td>\n",
       "      <td>0.293507</td>\n",
       "      <td>0.292190</td>\n",
       "      <td>-0.432188</td>\n",
       "      <td>-0.086024</td>\n",
       "      <td>0.127591</td>\n",
       "      <td>0.294884</td>\n",
       "      <td>0.360872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322598</th>\n",
       "      <td>441</td>\n",
       "      <td>-0.426640</td>\n",
       "      <td>-0.395375</td>\n",
       "      <td>-0.118199</td>\n",
       "      <td>-0.025609</td>\n",
       "      <td>-0.006464</td>\n",
       "      <td>-0.668986</td>\n",
       "      <td>-0.713861</td>\n",
       "      <td>-0.434418</td>\n",
       "      <td>-0.370745</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.053900</td>\n",
       "      <td>-0.972071</td>\n",
       "      <td>-0.732299</td>\n",
       "      <td>-0.675067</td>\n",
       "      <td>-0.630403</td>\n",
       "      <td>-1.031560</td>\n",
       "      <td>-0.916463</td>\n",
       "      <td>-0.657975</td>\n",
       "      <td>-0.612927</td>\n",
       "      <td>-0.531460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201659</th>\n",
       "      <td>320</td>\n",
       "      <td>-0.283726</td>\n",
       "      <td>0.102288</td>\n",
       "      <td>0.168105</td>\n",
       "      <td>0.249725</td>\n",
       "      <td>0.205908</td>\n",
       "      <td>-0.286051</td>\n",
       "      <td>0.126471</td>\n",
       "      <td>0.159916</td>\n",
       "      <td>0.222083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329505</td>\n",
       "      <td>-0.030041</td>\n",
       "      <td>-0.139086</td>\n",
       "      <td>-0.164751</td>\n",
       "      <td>-0.214723</td>\n",
       "      <td>-0.513602</td>\n",
       "      <td>-0.136303</td>\n",
       "      <td>-0.156735</td>\n",
       "      <td>-0.148623</td>\n",
       "      <td>-0.223685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fiberID  psfMag_u  psfMag_g  psfMag_r  psfMag_i  psfMag_z  \\\n",
       "id                                                                   \n",
       "70379        182 -0.598164 -0.562223 -0.523825 -0.477533 -0.310329   \n",
       "863365       207  1.119119  0.994625  0.513011  0.379657  0.880492   \n",
       "40381        496 -0.554902 -0.365210 -0.161029  0.063084  0.210503   \n",
       "1322598      441 -0.426640 -0.395375 -0.118199 -0.025609 -0.006464   \n",
       "1201659      320 -0.283726  0.102288  0.168105  0.249725  0.205908   \n",
       "\n",
       "         fiberMag_u  fiberMag_g  fiberMag_r  fiberMag_i     ...      \\\n",
       "id                                                          ...       \n",
       "70379     -0.608080   -0.527150   -0.404767   -0.334387     ...       \n",
       "863365     1.220576    1.098720    0.624629    0.501348     ...       \n",
       "40381     -0.583157   -0.319391   -0.059566    0.179141     ...       \n",
       "1322598   -0.668986   -0.713861   -0.434418   -0.370745     ...       \n",
       "1201659   -0.286051    0.126471    0.159916    0.222083     ...       \n",
       "\n",
       "         petroMag_u  petroMag_g  petroMag_r  petroMag_i  petroMag_z  \\\n",
       "id                                                                    \n",
       "70379     -0.478094   -0.270581   -0.174649   -0.128071   -0.048439   \n",
       "863365     1.411041    1.119810    0.692548    0.557135    0.774780   \n",
       "40381     -0.447007   -0.086297    0.132123    0.293507    0.292190   \n",
       "1322598   -1.053900   -0.972071   -0.732299   -0.675067   -0.630403   \n",
       "1201659   -0.329505   -0.030041   -0.139086   -0.164751   -0.214723   \n",
       "\n",
       "         modelMag_u  modelMag_g  modelMag_r  modelMag_i  modelMag_z  \n",
       "id                                                                   \n",
       "70379     -0.486939   -0.255689   -0.172579   -0.128800   -0.029025  \n",
       "863365     1.610314    1.099636    0.701630    0.549078    0.871485  \n",
       "40381     -0.432188   -0.086024    0.127591    0.294884    0.360872  \n",
       "1322598   -1.031560   -0.916463   -0.657975   -0.612927   -0.531460  \n",
       "1201659   -0.513602   -0.136303   -0.156735   -0.148623   -0.223685  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Robust scaling\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "columns = train.columns[2:22]\n",
    "rb_scaler = RobustScaler()\n",
    "train_test = pd.concat((train.iloc[:, 2:22], test.iloc[:, 1:]), axis=0)\n",
    "train_test = pd.DataFrame(rb_scaler.fit_transform(train_test), columns=columns, \n",
    "                          index=(list(train.index) + list(test.index)))\n",
    "\n",
    "train_scaled = train_test.iloc[:len(train.index), :]\n",
    "test_scaled = train_test.iloc[len(train.index):, :]\n",
    "train = pd.concat((train.iloc[:, 0:2], train_scaled, train.iloc[:, 22]), axis=1)\n",
    "test = pd.concat((test.iloc[:, 0], test_scaled), axis=1)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(columns=['type', 'type_num'], axis=1)\n",
    "train_y = train['type_num']\n",
    "test_x = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the optimal LGBM model with RandomCV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(n_jobs=-1)\n",
    "boosting_type = ['gbdt']\n",
    "num_leaves = [15,31,63]\n",
    "n_estimators = [1000, 1500, 2000]\n",
    "learning_rate = [0.05, 0.01, 0.001]\n",
    "\n",
    "parameter = {'num_leaves':num_leaves,\n",
    "            'boosting_type':boosting_type,\n",
    "            'n_estimators':n_estimators,\n",
    "             'learning_rate':learning_rate}\n",
    "\n",
    "rs_lgbm = RandomizedSearchCV(estimator=lgbm, \n",
    "                             param_distributions=parameter, \n",
    "                             scoring='neg_log_loss',\n",
    "                             n_jobs=-1)\n",
    "\n",
    "rs_lgbm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.001, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=1500, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "-0.8155246504154905\n"
     ]
    }
   ],
   "source": [
    "#Optimal LGBM model\n",
    "\n",
    "print(rs_lgbm.best_estimator_)\n",
    "print(rs_lgbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the optimal Randomforest model with RandomCV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "criterion = ['gini', 'entropy']\n",
    "num_leaves = [31,63,127]\n",
    "n_estimators = [1000, 1500, 2000]\n",
    "parameter = {'criterion':criterion,\n",
    "            'num_leaves':num_leaves,\n",
    "            'n_estimators':n_estimators}\n",
    "\n",
    "rs_rf = RandomizedSearchCV(estimator=lgbm, \n",
    "                             param_distributions=parameter, \n",
    "                             scoring='neg_log_loss',\n",
    "                             n_jobs=-1)\n",
    "\n",
    "rs_rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The optimal Randomforest model\n",
    "\n",
    "print(rs_lgbm.best_estimator_)\n",
    "print(rs_lgbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the optimal SVM model with RandomCV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(probability=True, n_jobs=-1)\n",
    "kernel = ['linear', 'poly', 'rbf']\n",
    "C = [0.1, 1, 10, 100]\n",
    "gamma = [0.1, 1, 10, 100]\n",
    "\n",
    "parameter = {'kernel':kernel,\n",
    "            'C':C,\n",
    "            'gamma':gamma}\n",
    "\n",
    "rs_svm = RandomizedSearchCV(estimator=svm, \n",
    "                             param_distributions=parameter, \n",
    "                             scoring='neg_log_loss',\n",
    "                             n_jobs=-1)\n",
    "\n",
    "\n",
    "rs_svm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The optimal SVM model\n",
    "\n",
    "print(rs_svm.best_estimator_)\n",
    "print(rs_svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking the data based on stratified cross-validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_stacking_data(model, X_train, y_train, X_test, n_folds=5):\n",
    "    stkf = StratifiedKFold(n_splits=n_folds)\n",
    "    \n",
    "    train_fold_pred = np.zeros((X_train.shape[0],1))\n",
    "    test_pred = np.zeros((X_test.shape[0], n_folds))\n",
    "    print(\"model :\", model.__class__.__name__)\n",
    "    \n",
    "    for i, (train_index, valid_index) in enumerate(stkf.split(X_train, y_train)):\n",
    "        X_train_fold = X_train.loc[train_index]\n",
    "        y_train_fold = y_train.loc[train_index]\n",
    "        X_val = X_train.loc[valid_index]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_val).reshape(-1, 1)\n",
    "        test_pred[:, i] = model.predict(X_test)\n",
    "        \n",
    "    test_pred_mean = np.mean(test_predict, axis=1).reshape(-1,1)\n",
    "    \n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/space/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/space/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/space/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/space/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/space/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/space/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/space/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/space/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/space/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/space/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-abf1ba24b9d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                           num_leaves=127)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlgbm_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgbm_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stacking_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbm_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-5e522e1af488>\u001b[0m in \u001b[0;36mget_stacking_data\u001b[0;34m(model, X_train, y_train, X_test, n_folds)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtest_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtest_pred_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_fold_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_predict' is not defined"
     ]
    }
   ],
   "source": [
    "#Stack the data with the optimal models\n",
    "\n",
    "xgb_opt = xgb()\n",
    "rf_opt = RandomForestClassifier()\n",
    "cat_opt = catboost()\n",
    "\n",
    "xgb_train, xgb_test = get_stacking_data(lgbm_opt, train_x, train_y, test_x, n_folds=5)\n",
    "rf_train, rf_test = get_stacking_data(rf_opt, train_x, train_y, test_x, n_folds=5)\n",
    "cat_train, cat_test = get_stacking_data(svm_opt, train_x, train_y, test_x, n_folds=5)\n",
    "\n",
    "stacked_X_train = np.concat((xgb_train, rf_train, cat_train), axis=1)\n",
    "stacked_X_test = np.concat((xgb_test, rf_test, cat_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.fit(stacked_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=y_pred, columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('submission.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
